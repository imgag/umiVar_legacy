#!/usr/bin/env pythonimport argparseimport pandas as pdimport randomimport scipy.statsimport reimport numpyimport timeitnumpy.seterr(divide = 'ignore')start = timeit.default_timer()## Functionsdef variant_type(ref, alt):    if (len(ref) > 1 or len(alt) > 1):        return 1    else:        return 0   def Vcalling(Fisher, Pval_o_adj, AC, Filter):    if (Fisher >= 1 and        Pval_o_adj > 0.05 and        bool(re.search('LC_', Filter)) != True and        bool(re.search('Variant_contamination', Filter)) != True):        return (1)    else:        return (0)    ### Read parametersparser = argparse.ArgumentParser(description='Benchmarking MRD')parser.add_argument('--infile', required=True, help='Input tsv file.')parser.add_argument('--outfile', required=True, help='Output MRD-tsv file.')parser.add_argument('--bed', required=True, help='0-based file, and not collapsed with the sites with simulated mutations')parser.add_argument('--hge', required=True, type=int, help='Number of HGe expected')parser.add_argument('--vaf', required=False, default='NA', help='Variant allele frequency simulated')args = ''try:    args = parser.parse_args()except IOError as io:    print io    sys.exit('Error reading parameters.')## Bed file with mutationsBED=args.bedbed=pd.read_csv(BED, sep = '\t', header=None)bed['site'] = bed.apply(lambda row : str(row[0]) + ';' +                     str(row[2]), axis = 1) # Encoded sitesB = set(bed['site'])## Haploid genome equivalentsHGE = args.hge## Variant allele frequency expectedVAF = args.vaf## Infile tsvinfile=args.infiledata = pd.read_csv(infile, sep = '\t')# Creating new columns in HGE and VAFdata['HGE'] = HGEdata['VAF'] = VAF# Creating index and checking if are true mutated sites or reference sitesdata['site'] = data.apply(lambda row : str(row['CHROM']) + ';' +                     str(row['POS']), axis = 1) data['Variant'] = data.apply(lambda row : row['site'] in B, axis = 1) # Checking if observed INDEL, SNV or nothing. For MRD, only SNV should be used, as INDELs have greater error ratesdata['Type'] = data.apply(lambda row : variant_type(row['REF'], row['ALT']), axis = 1)# Checking only high quality sites removing sites prone to be errorsdata['PASS'] = data.apply(lambda row : Vcalling(row['FISHER'], row['P_VALo_adj'], row['ALT_COUNT'], row['FILTER']), axis = 1)data2 = data[(data['PASS'] == 1) & (data['DP_HQ'] >= data['HGE']*0.9) & (data['Type'] == 0)].copy()# Getting True variant tableTRUE = data2[(data2['Variant'] == True)].copy()# Getting Ref tableREF = data2[(data2['Variant'] == False)].copy()# Getting p-values for each grouppvalues_true = list(TRUE['P_VAL'])pvalues_ref = list(REF['P_VAL'])# Random seedrandom.seed(1111)# Run the script for different NMRD = []REPLICATES = 100for repl in range(1, REPLICATES + 1):    for N in range(1, 151, 1):                # List to append final MRD values        N_replicates_true = []        N_replicates_ref = []                # Replicate the experiment for each N different times        TOTAL = 1000        for i in range(1, TOTAL + 1):                        # Selecting random Ps            P_sample_true = random.sample(pvalues_true, N)            P_sample_ref = random.sample(pvalues_ref, N)                        # Get simulation for true sites            SIMULATION_true = scipy.stats.combine_pvalues(P_sample_true, method = 'fisher')[1]            N_replicates_true.append(SIMULATION_true)                        # Get simulation for true sites            SIMULATION_ref = scipy.stats.combine_pvalues(P_sample_ref, method = 'fisher')[1]            N_replicates_ref.append(SIMULATION_ref)                                # Check how many significant replicates in ref sites and true mutated sites            TRUE_sig = len([x for x in range(0, len(N_replicates_true)) if N_replicates_true[x] < 0.05])        PROP_TRUE_sig = round( float(TRUE_sig) / TOTAL, 4 )                REF_sig = len([x for x in range(0, len(N_replicates_ref)) if N_replicates_ref[x] < 0.05])        PROP_REF_sig = round( float(REF_sig) / TOTAL, 4 )            # Benchmarking dataframe        MRD_TEMP = {'N':[N], 'Replicate':[repl], 'HGE':[HGE], 'VAF':[VAF], 'Total':[TOTAL],            'TRUE_sig':[TRUE_sig], 'REF_sig':[REF_sig], 'PROP_TRUE_sig':[PROP_TRUE_sig], 'PROP_REF_sig':[PROP_REF_sig]}                    MRD_TEMP_df = pd.DataFrame(MRD_TEMP, columns=['HGE', 'VAF', 'N', 'Replicate', 'Total', 'TRUE_sig', 'REF_sig', 'PROP_TRUE_sig', 'PROP_REF_sig'])                MRD.append(MRD_TEMP_df)# Concatenate MRD dataframeMRD_df = pd.concat(MRD, axis = 0)# Writing final outputMRD_df.to_csv(index=False, sep = '\t', path_or_buf =args.outfile)stop = timeit.default_timer()print 'TIME'print stop - startexit(0)