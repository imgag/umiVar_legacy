#!/usr/bin/env pythonimport pandas as pdimport randomimport statsmodels.stats.multitest as multiimport reimport timeitimport argparsestart = timeit.default_timer()# Function to check if site is the mutated or not mutated one def p_adjust(a, b):    b.insert(0,a)    P = multi.multipletests(b, method ='fdr_bh')[1][0]    return Pdef variant_type(ref, alt):    if (len(ref) > 1 or len(alt) > 1):        return 1    else:        return 0# Variant calling functiondef Vcalling(Fisher, Pval2, Pval_o_adj, AC, Filter):    if (Fisher >= 1 and        Pval2 <= 0.05 and        Pval_o_adj > 0.05 and        AC > 1 and        bool(re.search('LC_', Filter)) != True and        bool(re.search('Variant_contamination', Filter)) != True):        return (1)    else:        return (0)        ### Read parametersparser = argparse.ArgumentParser(description='Benchmarking variant calling')parser.add_argument('--infile', required=True, help='Input tsv file.')parser.add_argument('--outfile', required=True, help='Output tsv file (use prefix, extension will be added).')parser.add_argument('--bed', required=True, help='0-based file, and not collapsed with the sites with simulated mutations')parser.add_argument('--hge', required=True, type=int, help='Number of HGe expected')parser.add_argument('--vaf', required=False, default='NA', help='Variant allele frequency simulated')parser.add_argument('--error_rate', required=False, default='NA', help='Expected error rate')args = ''try:    args = parser.parse_args()except IOError as io:    print io    sys.exit('Error reading parameters.')    ## Bed file with mutationsBED=args.bedbed=pd.read_csv(BED, sep = '\t', header=None)bed['site'] = bed.apply(lambda row : str(row[0]) + ';' +                     str(row[2]), axis = 1) # Encoded sitesB = set(bed['site'])## Haploid genome equivalentsHGE = args.hge## Variant allele frequency expectedVAF = args.vaf## Error rateError_rate = args.error_rate## Infile tsvinfile=args.infiledata = pd.read_csv(infile, sep = '\t')# Creating new columns in HGE and VAFdata['HGE'] = HGEdata['VAF'] = VAFdata['Error_rate'] = Error_rate# Creating index and checking if are true mutated sites or reference sitesdata['site'] = data.apply(lambda row : str(row['CHROM']) + ';' +                     str(row['POS']), axis = 1) data['Variant'] = data.apply(lambda row : row['site'] in B, axis = 1) # Checking if observed INDEL, SNV or nothing. For MRD, only SNV should be used, as INDELs have greater error ratesdata['Type'] = data.apply(lambda row : variant_type(row['REF'], row['ALT']), axis = 1)# Creating True variant tableTRUE = data[(data['Variant'] == True) &  (data['DP_HQ'] >= data['HGE']*0.9)].copy()LEN_TRUE = len(TRUE['Variant'])# Creating Ref tableREF = data[(data['Variant'] == False) & (data['DP_HQ'] >= data['HGE']*0.9)].copy()# Reference p-values to include in the FDR correctionREF_pvalues = list(REF['P_VAL'])# Generate Ns (variant to select) to simulateALL = []BENCHMARK = []for repl in range(1, 101):    RANDOM_REF = REF.sample(n=LEN_TRUE, random_state = repl, replace = False)    #print repl    for N in ([1, 5] + range(10, 50, 10) ):        random.seed(repl)                # Sample P        P_sample = random.sample(REF_pvalues, N-1)                ## Variant calling        # Getting new P-values based on fdr correction for true variants        TRUE['P_VAL2'] = TRUE.apply(lambda row : p_adjust(row['P_VAL'], P_sample), axis = 1)        # Variant calling        TRUE['CALL'] = TRUE.apply(lambda row : Vcalling(row['FISHER'], row['P_VAL2'], row['P_VALo_adj'], row['ALT_COUNT'], row['FILTER']), axis = 1)        TRUE['N'] = N        TRUE['Replicate'] = repl                # Getting new P-values based on fdr correction for reference random sites        RANDOM_REF['P_VAL2'] = RANDOM_REF.apply(lambda row : p_adjust(row['P_VAL'], P_sample), axis = 1)        # Variant calling        RANDOM_REF['CALL'] = RANDOM_REF.apply(lambda row : Vcalling(row['FISHER'], row['P_VAL2'], row['P_VALo_adj'], row['ALT_COUNT'], row['FILTER']), axis = 1)            RANDOM_REF['N'] = N        RANDOM_REF['Replicate'] = repl            # Creating the global calls        TEMP = pd.concat([TRUE, RANDOM_REF], axis = 0)        ALL.append(TEMP)                    ## Benchmarking        # Checking true calls        TP = TRUE['CALL'].sum()        FN = len(TRUE['CALL']) - TP                # Checking ref sites        FP_df = RANDOM_REF[(RANDOM_REF['CALL'] == 1)].copy()           FP = RANDOM_REF['CALL'].sum()        FP_indel = FP_df['Type'].sum()        FP_snv = FP - FP_indel        TN = len(RANDOM_REF['CALL']) - FP                # Stats        Total_sites = TP + FN + FP + TN        Recall = round(float(TP) / (TP + FN), 4)        FPR = round(float(FP) / (FP + TN), 4)        FPR_indel = round(float(FP_indel) / (FP + TN), 4)        FPR_snv = round(float(FP_snv) / (FP + TN), 4)        ACC = round((float(TP) + TN) / (TP + TN + FP + FN), 4)                # Benchmarking dataframe        BENCH_TEMP = {'TP':[TP], 'FN':[FN], 'FP':[FP], 'FP_snv':[FP_snv], 'FP_indel':[FP_indel], 'TN':[TN], 'HGE':[HGE],            'Error_rate':[Error_rate], 'VAF':[VAF], 'N':[N], 'Replicate':[repl],            'Total_sites':[Total_sites], 'Recall':[Recall], 'FPR':[FPR], 'FPR_snv':[FPR_snv], 'FPR_indel':[FPR_indel], 'ACC':[ACC]}                BENCH_TEMP_df = pd.DataFrame(BENCH_TEMP, columns=['HGE', 'Error_rate', 'N', 'Replicate', 'Total_sites', 'TP', 'FN', 'FP', 'FP_snv', 'FP_indel', 'TN', 'Recall', 'FPR', 'FPR_snv', 'FPR_indel', 'ACC'])        BENCHMARK.append(BENCH_TEMP_df)  # Concatenate all data frames    ALL_final = pd.concat(ALL, axis = 0)BENCHMARKING = pd.concat(BENCHMARK, axis = 0)# Print data frames with benchmark and replicatesOUTFILE1 = args.outfile + '.vcalling.benchmarking.tsv'OUTFILE2 = args.outfile + '.vcalling.benchmarking.replicate_calls.tsv'BENCHMARKING.to_csv(index=False, sep = '\t', path_or_buf =  OUTFILE1)ALL_final.to_csv(index=False, sep = '\t', path_or_buf = OUTFILE2)# Running timestop = timeit.default_timer()print 'TIME'print stop - startexit(0)